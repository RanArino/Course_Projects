{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 04\n",
    "\n",
    "- Name: Ran Arino\n",
    "- Student ID: 153073200\n",
    "- Email: rarino@myseneca.ca\n",
    "- Course: Social Media Analytics\n",
    "- Course ID: BDA600NAA.07578.2241\n",
    "- Professor: Dr. Pantea Koochemeshkian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import statistics\n",
    "\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ZubairSabirPTI  pls dont insult the word 'Molna'</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ArcticFantasy I would have almost took offens...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@IllinoisLoyalty that Rutgers game was an abom...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@CozanGaming that's what lisa asked before she...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sometimes I get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets emotion\n",
       "0  @ZubairSabirPTI  pls dont insult the word 'Molna'   anger\n",
       "1  @ArcticFantasy I would have almost took offens...   anger\n",
       "2  @IllinoisLoyalty that Rutgers game was an abom...   anger\n",
       "3  @CozanGaming that's what lisa asked before she...   anger\n",
       "4  Sometimes I get mad over something so minuscul...   anger"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "# for training\n",
    "data = pd.read_excel('data/TweetEmotionDataset.xlsx', header=None)\n",
    "data = data.rename(columns={0: \"tweets\", 1: \"emotion\"})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>At the point today where if someone says somet...</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@CorningFootball  IT'S GAME DAY!!!!      T MIN...</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This game has pissed me off more than any othe...</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@spamvicious I've just found out it's Candice ...</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@moocowward @mrsajhargreaves @Melly77 @GaryBar...</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets emotion\n",
       "0  At the point today where if someone says somet...       ?\n",
       "1  @CorningFootball  IT'S GAME DAY!!!!      T MIN...       ?\n",
       "2  This game has pissed me off more than any othe...       ?\n",
       "3  @spamvicious I've just found out it's Candice ...       ?\n",
       "4  @moocowward @mrsajhargreaves @Melly77 @GaryBar...       ?"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for testing\n",
    "testing = pd.read_excel('data/test_dataset.xlsx', header=None)\n",
    "testing = testing.rename(columns={0: \"tweets\", 1: \"emotion\"})\n",
    "testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>emotion</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ZubairSabirPTI  pls dont insult the word 'Molna'</td>\n",
       "      <td>anger</td>\n",
       "      <td>pls dont insult word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ArcticFantasy I would have almost took offens...</td>\n",
       "      <td>anger</td>\n",
       "      <td>take offense snap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@IllinoisLoyalty that Rutgers game was an abom...</td>\n",
       "      <td>anger</td>\n",
       "      <td>game abomination affront man speak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@CozanGaming that's what lisa asked before she...</td>\n",
       "      <td>anger</td>\n",
       "      <td>ask start rag call heh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sometimes I get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>get mad something minuscule try ruin life lose...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets emotion  \\\n",
       "0  @ZubairSabirPTI  pls dont insult the word 'Molna'   anger   \n",
       "1  @ArcticFantasy I would have almost took offens...   anger   \n",
       "2  @IllinoisLoyalty that Rutgers game was an abom...   anger   \n",
       "3  @CozanGaming that's what lisa asked before she...   anger   \n",
       "4  Sometimes I get mad over something so minuscul...   anger   \n",
       "\n",
       "                                          clean_text  \n",
       "0                               pls dont insult word  \n",
       "1                                  take offense snap  \n",
       "2                 game abomination affront man speak  \n",
       "3                             ask start rag call heh  \n",
       "4  get mad something minuscule try ruin life lose...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning the texts\n",
    "def clean_texts(raw_texts: list or np.array):\n",
    "    # define result\n",
    "    result = []\n",
    "\n",
    "    # set of stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # initialize tweet tokenizer\n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    # set the lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # function to convert emojis to text\n",
    "    def convert_emojis(text):\n",
    "        return emoji.demojize(text, delimiters=(\"\", \"\"))\n",
    "    \n",
    "    # function to get the wordnet pos\n",
    "    def get_wordnet_pos(tag):\n",
    "        if tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        else:\n",
    "            # Default to noun\n",
    "            return wordnet.NOUN\n",
    "\n",
    "    # traversing all sentences\n",
    "    for sent in raw_texts:\n",
    "        # (1): white space removal\n",
    "        sent = sent.strip()\n",
    "        # (2): URL removal\n",
    "        sent = re.sub(r\"http[s]?://[\\w?\\W?]+\", '', sent)\n",
    "        # (3): HTML tag removal\n",
    "        sent = re.sub(r'<[^>]+>', '', sent)\n",
    "        # (4): Repeated words (at least four times)\n",
    "        sent = re.sub(r'(.)\\1{4,}', r'\\1', sent)\n",
    "        # (5): split attached words (at least two characters and follow the capitalized word)\n",
    "        sent = re.sub(r\"([\\w]{2,})([A-Z])\", r\"\\1 \\2\", sent)\n",
    "        # (6): Punctuation removal\n",
    "        sent = re.sub(r'[^\\w\\s]', '', sent)\n",
    "        # (7): Emoji to text\n",
    "        sent = convert_emojis(sent)\n",
    "        # (8): lemmatizaiton & tokenization\n",
    "        token = tweet_tokenizer.tokenize(sent)\n",
    "        tagged_token = nltk.pos_tag(token)\n",
    "        lemma_token = [\n",
    "            lemmatizer.lemmatize(w[0], get_wordnet_pos(w[1]))\n",
    "            for w in tagged_token\n",
    "            # # adjective ('JJ', 'JJR', 'JJS'), noun ('NN', 'NNP'), verb('VB', 'VBD', 'VBG', 'VBN', 'VBP')\n",
    "            if w[1] in ['JJ', 'JJR', 'JJS', 'NN', 'VB', 'VBD', 'VBG', 'VBN', 'VBP']\n",
    "        ]\n",
    "        # defined cleaned sentence\n",
    "        clean_sent = ''\n",
    "    \n",
    "        # cleaning each sentence\n",
    "        for w in lemma_token:\n",
    "            # if 'w' is one of stop words, skip to the next word\n",
    "            if w.lower() in stop_words:\n",
    "                continue\n",
    "            # add words\n",
    "            clean_sent += w.lower() + ' '\n",
    "\n",
    "        # add clean_sent to result (make sure that the last item is always blank)\n",
    "        result += [clean_sent[:-1]]\n",
    "\n",
    "    return result\n",
    "\n",
    "# add clean text to the dataset\n",
    "data.loc[:, 'clean_text'] = clean_texts(np.array(data['tweets'].values))\n",
    "testing.loc[:, 'clean_text'] = clean_texts(np.array(testing['tweets'].values))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>emotion</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ZubairSabirPTI  pls dont insult the word 'Molna'</td>\n",
       "      <td>anger</td>\n",
       "      <td>pls dont insult word</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ArcticFantasy I would have almost took offens...</td>\n",
       "      <td>anger</td>\n",
       "      <td>take offense snap</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@IllinoisLoyalty that Rutgers game was an abom...</td>\n",
       "      <td>anger</td>\n",
       "      <td>game abomination affront man speak</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@CozanGaming that's what lisa asked before she...</td>\n",
       "      <td>anger</td>\n",
       "      <td>ask start rag call heh</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sometimes I get mad over something so minuscul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>get mad something minuscule try ruin life lose...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets emotion  \\\n",
       "0  @ZubairSabirPTI  pls dont insult the word 'Molna'   anger   \n",
       "1  @ArcticFantasy I would have almost took offens...   anger   \n",
       "2  @IllinoisLoyalty that Rutgers game was an abom...   anger   \n",
       "3  @CozanGaming that's what lisa asked before she...   anger   \n",
       "4  Sometimes I get mad over something so minuscul...   anger   \n",
       "\n",
       "                                          clean_text  anger  fear  joy  \\\n",
       "0                               pls dont insult word      1     0    0   \n",
       "1                                  take offense snap      1     0    0   \n",
       "2                 game abomination affront man speak      1     0    0   \n",
       "3                             ask start rag call heh      1     0    0   \n",
       "4  get mad something minuscule try ruin life lose...      1     0    0   \n",
       "\n",
       "   sadness  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new columns with binary values\n",
    "for emotion in np.unique(data['emotion']):\n",
    "    data[emotion] = data['emotion'].apply(lambda x: 1 if x == emotion else 0)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\runru\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explnatory Variable format: \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Target Variable format: \n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# apply tf-idf\n",
    "# create TF-IDF vectrizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "# fit and transform data\n",
    "matrix = tfidf_vect.fit_transform(np.array(data.loc[:, 'clean_text']))\n",
    "\n",
    "# get the explanatory and target variables for machine learning\n",
    "X = matrix.toarray()\n",
    "# assign the emotion that we wanna predict here; in this case \"fear\"\n",
    "y = np.array(data['fear'])\n",
    "\n",
    "\n",
    "print(\"Explnatory Variable format: \")\n",
    "print(X[:5])\n",
    "\n",
    "print(\"\\nTarget Variable format: \")\n",
    "print(y[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y, random_state=10)\n",
    "\n",
    "# class weights\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = {k: v for k, v in zip(classes, class_weights)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "18/18 [==============================] - 1s 15ms/step - loss: 0.6919 - accuracy: 0.5523 - val_loss: 0.6888 - val_accuracy: 0.5857\n",
      "Epoch 2/15\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6639 - accuracy: 0.9495 - val_loss: 0.6754 - val_accuracy: 0.7429\n",
      "Epoch 3/15\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6124 - accuracy: 0.9892 - val_loss: 0.6462 - val_accuracy: 0.7714\n",
      "Epoch 4/15\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4984 - accuracy: 0.9928 - val_loss: 0.5877 - val_accuracy: 0.7714\n",
      "Epoch 5/15\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3186 - accuracy: 0.9964 - val_loss: 0.4836 - val_accuracy: 0.8143\n",
      "Epoch 6/15\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.1529 - accuracy: 0.9964 - val_loss: 0.4091 - val_accuracy: 0.8286\n",
      "Epoch 7/15\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9964 - val_loss: 0.3704 - val_accuracy: 0.8429\n",
      "Epoch 8/15\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0338 - accuracy: 0.9964 - val_loss: 0.3543 - val_accuracy: 0.8714\n",
      "Epoch 9/15\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0217 - accuracy: 0.9964 - val_loss: 0.3510 - val_accuracy: 0.8714\n",
      "Epoch 10/15\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9964 - val_loss: 0.3510 - val_accuracy: 0.8714\n",
      "Epoch 11/15\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 0.3523 - val_accuracy: 0.8571\n",
      "Epoch 12/15\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.3478 - val_accuracy: 0.8857\n",
      "Epoch 13/15\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.3446 - val_accuracy: 0.8857\n",
      "Epoch 14/15\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.3430 - val_accuracy: 0.8857\n",
      "Epoch 15/15\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 0.3504 - val_accuracy: 0.8714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22a8b340390>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural Network Model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=16, validation_data=(X_test, y_test), class_weight=class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022A8B32B7E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91        48\n",
      "           1       0.81      0.77      0.79        22\n",
      "\n",
      "    accuracy                           0.87        70\n",
      "   macro avg       0.85      0.84      0.85        70\n",
      "weighted avg       0.87      0.87      0.87        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test) >= 0.5).astype(int).flatten()\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WS04_Neuraletwork.joblib']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# save model\n",
    "import joblib\n",
    "joblib.dump(model, 'WS04_Neuraletwork.joblib')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the model for testing data\n",
    "testing_matrix = tfidf_vect.transform(np.array(testing.loc[:, 'clean_text']))\n",
    "testing_data = testing_matrix.toarray()\n",
    "\n",
    "# generate prediction\n",
    "y_pred_testing = (model.predict(testing_data) >= 0.5).astype(int).flatten()\n",
    "y_pred_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing down the predicted label in TXT format\n",
    "\n",
    "with open(\"WS04_prediction.txt\", 'w') as f:\n",
    "    f.write(\"\\n\".join(np.where(y_pred_testing == 1, 'fear', 'other')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
