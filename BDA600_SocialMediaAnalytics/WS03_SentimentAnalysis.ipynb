{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 03\n",
    "\n",
    "- Name: Ran Arino\n",
    "- Student ID: 153073200\n",
    "- Email: rarino@myseneca.ca\n",
    "- Course: Social Media Analytics\n",
    "- Course ID: BDA600NAA.07578.2241\n",
    "- Professor: Dr. Pantea Koochemeshkian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import statistics\n",
    "\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.downloader import base_dir, load\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.260000e+17</td>\n",
       "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.260000e+17</td>\n",
       "      <td>@Apple will be adding more carrier support to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.260000e+17</td>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.260000e+17</td>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.260000e+17</td>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment       TweetId                                          TweetText\n",
       "0  positive  1.260000e+17  Now all @Apple has to do is get swype on the i...\n",
       "1  positive  1.260000e+17  @Apple will be adding more carrier support to ...\n",
       "2  positive  1.260000e+17  Hilarious @youtube video - guy does a duet wit...\n",
       "3  positive  1.260000e+17  @RIM you made it too easy for me to switch to ...\n",
       "4  positive  1.260000e+17  I just realized that the reason I got into twi..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data set from data folder\n",
    "data = pd.read_csv(\"data/full-corpus-training.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "neutral     2228\n",
       "negative     437\n",
       "positive     329\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the rows whose \"Sentiment\" column is \"irrelevant\"\n",
    "new_data = data[data['Sentiment'] != 'irrelevant']\n",
    "new_data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['appl get swype iphon crack iphon',\n",
       " 'appl ad carrier support iphon announc',\n",
       " 'hilari video guy duet much love affair',\n",
       " 'ri made easi switch appl iphon see ya',\n",
       " 'realiz reason got twitter io appl']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning the texts\n",
    "def clean_texts(raw_texts: list or np.array, tagging: bool = False):\n",
    "    # define result\n",
    "    result = []\n",
    "\n",
    "    # set of stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # set the porter stemming\n",
    "    porter = nltk.PorterStemmer()\n",
    "    # initialize tweet tokenizer\n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "    # function to convert emojis to text\n",
    "    def convert_emojis(text):\n",
    "        return emoji.demojize(text, delimiters=(\"\", \"\"))\n",
    "\n",
    "    # traversing all sentences\n",
    "    for sent in raw_texts:\n",
    "        # apply tagging\n",
    "        if tagging:\n",
    "            token = tweet_tokenizer.tokenize(sent)\n",
    "            tagged_words = nltk.pos_tag(token)\n",
    "            # adjective ('JJ', 'JJR', 'JJS'), noun ('NN', 'NNP'), verb('VB', 'VBD', 'VBG', 'VBN', 'VBP')\n",
    "            sent = \" \".join([w[0] for w in tagged_words if w[1] in ['JJ', 'JJR', 'JJS', 'NN', 'VB', 'VBD', 'VBG', 'VBN', 'VBP']])\n",
    "\n",
    "        # (1): white space removal\n",
    "        sent = sent.strip()\n",
    "        # (2): URL removal\n",
    "        sent = re.sub(r\"http[s]?://[\\w?\\W?]+\", '', sent)\n",
    "        # (3): HTML tag removal\n",
    "        sent = re.sub(r'<[^>]+>', '', sent)\n",
    "        # (4): Repeated words (at least four times)\n",
    "        sent = re.sub(r'(.)\\1{4,}', r'\\1', sent)\n",
    "        # (5): split attached words (at least two characters and follow the capitalized word)\n",
    "        sent = re.sub(r\"([\\w]{2,})([A-Z])\", r\"\\1 \\2\", sent)\n",
    "        # (6): Punctuation removal without @ and #\n",
    "        sent = re.sub(r'[^\\w\\s]', '', sent)\n",
    "        # (7): Emoji to text\n",
    "        sent = convert_emojis(sent)\n",
    "        # (8): toknize exclude punct\n",
    "        #tokens = nltk.regexp_tokenize(sent, r\"\\w+(?:'\\w+)?\")\n",
    "        #(8): tokenize with TweetTokenizer\n",
    "        tokens = tweet_tokenizer.tokenize(sent)\n",
    "\n",
    "        # defined cleaned sentence\n",
    "        clean_sent = ''\n",
    "    \n",
    "        # cleaning each sentence\n",
    "        for w in tokens:\n",
    "            # if 'w' is one of stop words, skip to the next word\n",
    "            if w.lower() in stop_words:\n",
    "                continue\n",
    "            # add words without stemming\n",
    "            clean_sent += porter.stem(w.lower()) + ' '\n",
    "            #clean_sent += w.lower() + ' '\n",
    "\n",
    "        # add clean_sent to result (make sure that the last item is always blank)\n",
    "        result += [clean_sent[:-1]]\n",
    "\n",
    "    return result\n",
    "\n",
    "# get the clean tweet data as list\n",
    "sent_list = clean_texts(np.array(new_data['TweetText'].values), True)\n",
    "sent_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>CleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.260000e+17</td>\n",
       "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
       "      <td>appl get swype iphon crack iphon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.260000e+17</td>\n",
       "      <td>@Apple will be adding more carrier support to ...</td>\n",
       "      <td>appl ad carrier support iphon announc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.260000e+17</td>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "      <td>hilari video guy duet much love affair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.260000e+17</td>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "      <td>ri made easi switch appl iphon see ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.260000e+17</td>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
       "      <td>realiz reason got twitter io appl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment       TweetId                                          TweetText  \\\n",
       "0  positive  1.260000e+17  Now all @Apple has to do is get swype on the i...   \n",
       "1  positive  1.260000e+17  @Apple will be adding more carrier support to ...   \n",
       "2  positive  1.260000e+17  Hilarious @youtube video - guy does a duet wit...   \n",
       "3  positive  1.260000e+17  @RIM you made it too easy for me to switch to ...   \n",
       "4  positive  1.260000e+17  I just realized that the reason I got into twi...   \n",
       "\n",
       "                                CleanText  \n",
       "0        appl get swype iphon crack iphon  \n",
       "1   appl ad carrier support iphon announc  \n",
       "2  hilari video guy duet much love affair  \n",
       "3   ri made easi switch appl iphon see ya  \n",
       "4       realiz reason got twitter io appl  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add clean text to the dataset\n",
    "new_data.loc[:, 'CleanText'] = sent_list\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "neutral     2228\n",
       "negative     437\n",
       "positive     329\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply tf-idf\n",
    "# create TF-IDF vectrizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "# fit and transform data\n",
    "matrix = tfidf_vect.fit_transform(sent_list)\n",
    "\n",
    "# get the explanatory and target variables for machine learning\n",
    "X = matrix.toarray()\n",
    "y = np.array(new_data['Sentiment'])\n",
    "# Encord the target varieble for nueral network\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_cat = to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explnatory Variable format: \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Target Variable format: \n",
      "['positive' 'positive' 'positive' 'positive' 'positive']\n",
      "\n",
      "Encorded Target Variable: \n",
      "['negative' 'neutral' 'positive']\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Explnatory Variable format: \")\n",
    "print(X[:5])\n",
    "\n",
    "print(\"\\nTarget Variable format: \")\n",
    "print(y[:5])\n",
    "\n",
    "print(\"\\nEncorded Target Variable: \")\n",
    "print(label_encoder.classes_)\n",
    "print(y_cat[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "# define the encoder for neural nerwork\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "# compute weights for imbalanced target variable (minimum: 0.8)\n",
    "classes = np.unique(y)\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=y)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "#class_weight_dict = {k: max(v, 0.8) for k, v in dict(enumerate(class_weights)).items()}\n",
    "\n",
    "# define statifired k-fold processes\n",
    "def strat_kfold(model_name, X, y, k=5):\n",
    "    # stratified k-fold cross validation\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    # fold number\n",
    "    i = 1\n",
    "    # performance func\n",
    "    perf_func = {\"Acc\": accuracy_score, \"Pre\": precision_score, \"Rec\": recall_score, \n",
    "                 \"F1\": f1_score, \"Conf\": confusion_matrix}\n",
    "    # set the dict of the performance results\n",
    "    results = {key: [] for key in perf_func.keys()}\n",
    "    # trained model at each validation\n",
    "    models = []\n",
    "    # apply k-hold cross validation\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        print(f\"start fold {i}\")\n",
    "        # set train data\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        # Neural Network\n",
    "        if model_name == 'neural_network':\n",
    "            # set test data\n",
    "            y_train, y_test = y_cat[train_index], y_cat[test_index]\n",
    "            # Neural Network Model\n",
    "            model = Sequential()\n",
    "            model.add(Dense(128, activation='tanh', input_shape=(X.shape[1],)))\n",
    "            model.add(Dense(32, activation='tanh'))\n",
    "            model.add(Dense(3, activation='softmax'))  # 3 units for 3 classes\n",
    "            # Compile the model\n",
    "            model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.2, class_weight=class_weight_dict)\n",
    "            # predict the target classes\n",
    "            y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "            # convert the y_test to\n",
    "            y_test = np.argmax(y_test, axis=1)\n",
    "            # add model\n",
    "            models.append(model)\n",
    "        # random forest\n",
    "        elif model_name == 'random_forest':\n",
    "            # set the test data\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            # set model\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=100, class_weight='balanced',\n",
    "                random_state=42, n_jobs=-1\n",
    "                )\n",
    "            # train the data into the model\n",
    "            model.fit(X_train, y_train)\n",
    "            # predict the target classes\n",
    "            y_pred = model.predict(X_test)\n",
    "            # add model\n",
    "            models.append(model)\n",
    "        # naive bayes\n",
    "        elif model_name == \"naive_bayes\":\n",
    "            # set the test data\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            # set model\n",
    "            model = MultinomialNB()\n",
    "            # train the data into the model\n",
    "            model.fit(X_train, y_train)\n",
    "            # predict the target classes\n",
    "            y_pred = model.predict(X_test)\n",
    "            # add model\n",
    "            models.append(model)\n",
    "\n",
    "        else:\n",
    "            return None, None, None\n",
    "\n",
    "        # calculate classificaiton performances\n",
    "        for key in perf_func.keys():\n",
    "            if key in [\"Acc\", \"Conf\"]:\n",
    "                params = {}\n",
    "            else:\n",
    "                params = {'average': 'macro'}\n",
    "                \n",
    "            results[key].append(perf_func[key](y_test, y_pred, **params))\n",
    "        \n",
    "        # increment fold\n",
    "        i += 1\n",
    "\n",
    "    # create the min-max confusion matrix\n",
    "    stacked_arrays = np.stack(results['Conf'], axis=0)\n",
    "    # Combine min and max values into a tuple for each component\n",
    "    min_max_conf = np.dstack((np.min(stacked_arrays, axis=0), np.max(stacked_arrays, axis=0)))\n",
    "\n",
    "    # delete \"Conf\" key from dict\n",
    "    del results['Conf']\n",
    "\n",
    "    return pd.DataFrame(results), min_max_conf, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fold 1\n",
      "start fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\runru\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\runru\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fold 3\n",
      "start fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\runru\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\runru\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fold 5\n",
      "[[[  0   5]\n",
      "  [ 83  87]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   1]\n",
      "  [445 446]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [ 65  66]\n",
      "  [  0   0]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\runru\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>Pre</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.746244</td>\n",
       "      <td>0.581798</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.299524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.744574</td>\n",
       "      <td>0.415131</td>\n",
       "      <td>0.336417</td>\n",
       "      <td>0.291927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.744574</td>\n",
       "      <td>0.248191</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.284530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.746244</td>\n",
       "      <td>0.471104</td>\n",
       "      <td>0.340249</td>\n",
       "      <td>0.299524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.752508</td>\n",
       "      <td>0.583474</td>\n",
       "      <td>0.352273</td>\n",
       "      <td>0.321648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Acc       Pre       Rec        F1\n",
       "0  0.746244  0.581798  0.340909  0.299524\n",
       "1  0.744574  0.415131  0.336417  0.291927\n",
       "2  0.744574  0.248191  0.333333  0.284530\n",
       "3  0.746244  0.471104  0.340249  0.299524\n",
       "4  0.752508  0.583474  0.352273  0.321648"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Classifiers\n",
    "nb_results, nb_conf, nb_models = strat_kfold(\"naive_bayes\", X, y)\n",
    "print(nb_conf)\n",
    "nb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fold 1\n",
      "start fold 2\n",
      "start fold 3\n",
      "start fold 4\n",
      "start fold 5\n",
      "[[[ 23  31]\n",
      "  [ 55  64]\n",
      "  [  0   2]]\n",
      "\n",
      " [[  8  14]\n",
      "  [420 429]\n",
      "  [  8  16]]\n",
      "\n",
      " [[  0   2]\n",
      "  [ 52  58]\n",
      "  [  6  13]]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>Pre</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.769616</td>\n",
       "      <td>0.614973</td>\n",
       "      <td>0.469632</td>\n",
       "      <td>0.499156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.772955</td>\n",
       "      <td>0.677561</td>\n",
       "      <td>0.464306</td>\n",
       "      <td>0.501356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.767947</td>\n",
       "      <td>0.649425</td>\n",
       "      <td>0.483006</td>\n",
       "      <td>0.521527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.767947</td>\n",
       "      <td>0.635151</td>\n",
       "      <td>0.478130</td>\n",
       "      <td>0.511537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.754181</td>\n",
       "      <td>0.589071</td>\n",
       "      <td>0.433995</td>\n",
       "      <td>0.458217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Acc       Pre       Rec        F1\n",
       "0  0.769616  0.614973  0.469632  0.499156\n",
       "1  0.772955  0.677561  0.464306  0.501356\n",
       "2  0.767947  0.649425  0.483006  0.521527\n",
       "3  0.767947  0.635151  0.478130  0.511537\n",
       "4  0.754181  0.589071  0.433995  0.458217"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randon forest\n",
    "rf_results, rf_conf, rf_models = strat_kfold(\"random_forest\", X, y)\n",
    "print(rf_conf)\n",
    "rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fold 1\n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 14ms/step - loss: 1.1419 - categorical_accuracy: 0.2912 - val_loss: 1.3534 - val_categorical_accuracy: 0.0230\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.6904 - categorical_accuracy: 0.6435 - val_loss: 1.7544 - val_categorical_accuracy: 0.1357\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.3334 - categorical_accuracy: 0.8486 - val_loss: 2.5080 - val_categorical_accuracy: 0.1336\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.1979 - categorical_accuracy: 0.8977 - val_loss: 2.3601 - val_categorical_accuracy: 0.2630\n",
      "Epoch 5/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.1415 - categorical_accuracy: 0.9405 - val_loss: 2.6257 - val_categorical_accuracy: 0.2693\n",
      "Epoch 6/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.1163 - categorical_accuracy: 0.9473 - val_loss: 2.6279 - val_categorical_accuracy: 0.3194\n",
      "Epoch 7/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.1014 - categorical_accuracy: 0.9582 - val_loss: 2.9132 - val_categorical_accuracy: 0.2923\n",
      "Epoch 8/15\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0934 - categorical_accuracy: 0.9546 - val_loss: 2.8015 - val_categorical_accuracy: 0.3528\n",
      "Epoch 9/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0880 - categorical_accuracy: 0.9609 - val_loss: 2.9137 - val_categorical_accuracy: 0.3466\n",
      "Epoch 10/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0884 - categorical_accuracy: 0.9546 - val_loss: 3.1365 - val_categorical_accuracy: 0.3257\n",
      "Epoch 11/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0818 - categorical_accuracy: 0.9614 - val_loss: 3.1265 - val_categorical_accuracy: 0.3486\n",
      "Epoch 12/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0815 - categorical_accuracy: 0.9635 - val_loss: 3.0381 - val_categorical_accuracy: 0.3862\n",
      "Epoch 13/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0844 - categorical_accuracy: 0.9567 - val_loss: 3.8378 - val_categorical_accuracy: 0.2255\n",
      "Epoch 14/15\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0801 - categorical_accuracy: 0.9640 - val_loss: 3.4865 - val_categorical_accuracy: 0.3257\n",
      "Epoch 15/15\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0804 - categorical_accuracy: 0.9556 - val_loss: 3.6459 - val_categorical_accuracy: 0.2756\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "start fold 2\n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 14ms/step - loss: 1.1539 - categorical_accuracy: 0.2839 - val_loss: 1.4675 - val_categorical_accuracy: 0.0146\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.6814 - categorical_accuracy: 0.6180 - val_loss: 1.7959 - val_categorical_accuracy: 0.1524\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3224 - categorical_accuracy: 0.8450 - val_loss: 2.2195 - val_categorical_accuracy: 0.2129\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.1895 - categorical_accuracy: 0.8888 - val_loss: 2.1969 - val_categorical_accuracy: 0.2610\n",
      "Epoch 5/15\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.1384 - categorical_accuracy: 0.9295 - val_loss: 2.2324 - val_categorical_accuracy: 0.3278\n",
      "Epoch 6/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.1124 - categorical_accuracy: 0.9572 - val_loss: 2.5899 - val_categorical_accuracy: 0.2672\n",
      "Epoch 7/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.1005 - categorical_accuracy: 0.9426 - val_loss: 2.3121 - val_categorical_accuracy: 0.3653\n",
      "Epoch 8/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0953 - categorical_accuracy: 0.9619 - val_loss: 2.5923 - val_categorical_accuracy: 0.3361\n",
      "Epoch 9/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0923 - categorical_accuracy: 0.9546 - val_loss: 2.4271 - val_categorical_accuracy: 0.3737\n",
      "Epoch 10/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0891 - categorical_accuracy: 0.9656 - val_loss: 3.0102 - val_categorical_accuracy: 0.3111\n",
      "Epoch 11/15\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0861 - categorical_accuracy: 0.9650 - val_loss: 2.7884 - val_categorical_accuracy: 0.3507\n",
      "Epoch 12/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0823 - categorical_accuracy: 0.9609 - val_loss: 2.9364 - val_categorical_accuracy: 0.3403\n",
      "Epoch 13/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0820 - categorical_accuracy: 0.9666 - val_loss: 3.2274 - val_categorical_accuracy: 0.2756\n",
      "Epoch 14/15\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0806 - categorical_accuracy: 0.9682 - val_loss: 3.2288 - val_categorical_accuracy: 0.3215\n",
      "Epoch 15/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0798 - categorical_accuracy: 0.9588 - val_loss: 3.0274 - val_categorical_accuracy: 0.3570\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "start fold 3\n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 14ms/step - loss: 1.1309 - categorical_accuracy: 0.2985 - val_loss: 1.4122 - val_categorical_accuracy: 0.0480\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.6521 - categorical_accuracy: 0.6519 - val_loss: 1.7435 - val_categorical_accuracy: 0.1503\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.3107 - categorical_accuracy: 0.8486 - val_loss: 2.3074 - val_categorical_accuracy: 0.1858\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.1874 - categorical_accuracy: 0.9081 - val_loss: 2.1707 - val_categorical_accuracy: 0.3194\n",
      "Epoch 5/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.1360 - categorical_accuracy: 0.9342 - val_loss: 2.0805 - val_categorical_accuracy: 0.3967\n",
      "Epoch 6/15\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.1141 - categorical_accuracy: 0.9452 - val_loss: 2.4786 - val_categorical_accuracy: 0.3299\n",
      "Epoch 7/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.1049 - categorical_accuracy: 0.9546 - val_loss: 2.4160 - val_categorical_accuracy: 0.3716\n",
      "Epoch 8/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0931 - categorical_accuracy: 0.9546 - val_loss: 2.9209 - val_categorical_accuracy: 0.3236\n",
      "Epoch 9/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0916 - categorical_accuracy: 0.9541 - val_loss: 2.5928 - val_categorical_accuracy: 0.3779\n",
      "Epoch 10/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0868 - categorical_accuracy: 0.9640 - val_loss: 2.5867 - val_categorical_accuracy: 0.3883\n",
      "Epoch 11/15\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0863 - categorical_accuracy: 0.9525 - val_loss: 2.5709 - val_categorical_accuracy: 0.4008\n",
      "Epoch 12/15\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0840 - categorical_accuracy: 0.9562 - val_loss: 2.6981 - val_categorical_accuracy: 0.3883\n",
      "Epoch 13/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0810 - categorical_accuracy: 0.9703 - val_loss: 3.0107 - val_categorical_accuracy: 0.3549\n",
      "Epoch 14/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0803 - categorical_accuracy: 0.9541 - val_loss: 2.8706 - val_categorical_accuracy: 0.3862\n",
      "Epoch 15/15\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0762 - categorical_accuracy: 0.9640 - val_loss: 3.1756 - val_categorical_accuracy: 0.3424\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "start fold 4\n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 1.1671 - categorical_accuracy: 0.3126 - val_loss: 1.5413 - val_categorical_accuracy: 0.0021\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.6909 - categorical_accuracy: 0.6487 - val_loss: 2.0671 - val_categorical_accuracy: 0.0939\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.3170 - categorical_accuracy: 0.8565 - val_loss: 2.5664 - val_categorical_accuracy: 0.1357\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.1714 - categorical_accuracy: 0.9118 - val_loss: 2.4263 - val_categorical_accuracy: 0.2923\n",
      "Epoch 5/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.1192 - categorical_accuracy: 0.9442 - val_loss: 2.2533 - val_categorical_accuracy: 0.3695\n",
      "Epoch 6/15\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0950 - categorical_accuracy: 0.9682 - val_loss: 2.4254 - val_categorical_accuracy: 0.3862\n",
      "Epoch 7/15\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0829 - categorical_accuracy: 0.9666 - val_loss: 2.8575 - val_categorical_accuracy: 0.3173\n",
      "Epoch 8/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0751 - categorical_accuracy: 0.9703 - val_loss: 2.7403 - val_categorical_accuracy: 0.3466\n",
      "Epoch 9/15\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0700 - categorical_accuracy: 0.9734 - val_loss: 2.9433 - val_categorical_accuracy: 0.3403\n",
      "Epoch 10/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0696 - categorical_accuracy: 0.9802 - val_loss: 3.0673 - val_categorical_accuracy: 0.3361\n",
      "Epoch 11/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0656 - categorical_accuracy: 0.9791 - val_loss: 2.9947 - val_categorical_accuracy: 0.3758\n",
      "Epoch 12/15\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0652 - categorical_accuracy: 0.9791 - val_loss: 3.4070 - val_categorical_accuracy: 0.3173\n",
      "Epoch 13/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.0671 - categorical_accuracy: 0.9744 - val_loss: 3.4583 - val_categorical_accuracy: 0.3194\n",
      "Epoch 14/15\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0646 - categorical_accuracy: 0.9739 - val_loss: 3.2897 - val_categorical_accuracy: 0.3653\n",
      "Epoch 15/15\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0636 - categorical_accuracy: 0.9786 - val_loss: 3.1841 - val_categorical_accuracy: 0.3653\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "start fold 5\n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 1.1333 - categorical_accuracy: 0.2766 - val_loss: 1.2862 - val_categorical_accuracy: 0.0479\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.6623 - categorical_accuracy: 0.6675 - val_loss: 1.6803 - val_categorical_accuracy: 0.1813\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.3049 - categorical_accuracy: 0.8570 - val_loss: 2.0601 - val_categorical_accuracy: 0.2479\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.1805 - categorical_accuracy: 0.9061 - val_loss: 2.0467 - val_categorical_accuracy: 0.3542\n",
      "Epoch 5/15\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.1296 - categorical_accuracy: 0.9363 - val_loss: 2.1387 - val_categorical_accuracy: 0.3708\n",
      "Epoch 6/15\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.1065 - categorical_accuracy: 0.9598 - val_loss: 2.4525 - val_categorical_accuracy: 0.3583\n",
      "Epoch 7/15\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.0917 - categorical_accuracy: 0.9640 - val_loss: 2.7053 - val_categorical_accuracy: 0.3604\n",
      "Epoch 8/15\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.0874 - categorical_accuracy: 0.9582 - val_loss: 2.4887 - val_categorical_accuracy: 0.4125\n",
      "Epoch 9/15\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0810 - categorical_accuracy: 0.9650 - val_loss: 2.8151 - val_categorical_accuracy: 0.3812\n",
      "Epoch 10/15\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.0815 - categorical_accuracy: 0.9650 - val_loss: 2.8238 - val_categorical_accuracy: 0.3917\n",
      "Epoch 11/15\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0746 - categorical_accuracy: 0.9645 - val_loss: 3.0227 - val_categorical_accuracy: 0.3771\n",
      "Epoch 12/15\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0748 - categorical_accuracy: 0.9697 - val_loss: 2.8458 - val_categorical_accuracy: 0.4104\n",
      "Epoch 13/15\n",
      "60/60 [==============================] - 1s 12ms/step - loss: 0.0749 - categorical_accuracy: 0.9666 - val_loss: 3.0542 - val_categorical_accuracy: 0.3938\n",
      "Epoch 14/15\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.0718 - categorical_accuracy: 0.9708 - val_loss: 3.2843 - val_categorical_accuracy: 0.3708\n",
      "Epoch 15/15\n",
      "60/60 [==============================] - 1s 13ms/step - loss: 0.0728 - categorical_accuracy: 0.9661 - val_loss: 3.3859 - val_categorical_accuracy: 0.3729\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "[[[ 41  51]\n",
      "  [ 28  37]\n",
      "  [  4  10]]\n",
      "\n",
      " [[ 42  73]\n",
      "  [236 321]\n",
      "  [ 70 153]]\n",
      "\n",
      " [[  4   8]\n",
      "  [ 23  32]\n",
      "  [ 27  37]]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>Pre</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.540902</td>\n",
       "      <td>0.486707</td>\n",
       "      <td>0.556830</td>\n",
       "      <td>0.478348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.661102</td>\n",
       "      <td>0.511300</td>\n",
       "      <td>0.560182</td>\n",
       "      <td>0.527206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.624374</td>\n",
       "      <td>0.500273</td>\n",
       "      <td>0.562817</td>\n",
       "      <td>0.511571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.631052</td>\n",
       "      <td>0.488263</td>\n",
       "      <td>0.550386</td>\n",
       "      <td>0.504514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.591973</td>\n",
       "      <td>0.499994</td>\n",
       "      <td>0.551788</td>\n",
       "      <td>0.494106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Acc       Pre       Rec        F1\n",
       "0  0.540902  0.486707  0.556830  0.478348\n",
       "1  0.661102  0.511300  0.560182  0.527206\n",
       "2  0.624374  0.500273  0.562817  0.511571\n",
       "3  0.631052  0.488263  0.550386  0.504514\n",
       "4  0.591973  0.499994  0.551788  0.494106"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neural network\n",
    "nw_results, nw_conf, nw_models = strat_kfold(\"neural_network\", X, y, k=5)\n",
    "print(nw_conf)\n",
    "nw_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126352268705538000</td>\n",
       "      <td>Come to the dark side üì±‚Äú@gretcheneclark: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126350302113824000</td>\n",
       "      <td>Hey @apple, if you send me a free iPhone (any ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126349695676203008</td>\n",
       "      <td>Thank you @apple for Find My Mac - just locate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126342268603998000</td>\n",
       "      <td>Thanks to @Apple Covent Garden #GeniusBar for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126325800080392000</td>\n",
       "      <td>@DailyDealChat @apple Thanks!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TweetId                                          TweetText\n",
       "0  126352268705538000  Come to the dark side üì±‚Äú@gretcheneclark: ...\n",
       "1  126350302113824000  Hey @apple, if you send me a free iPhone (any ...\n",
       "2  126349695676203008  Thank you @apple for Find My Mac - just locate...\n",
       "3  126342268603998000  Thanks to @Apple Covent Garden #GeniusBar for ...\n",
       "4  126325800080392000                     @DailyDealChat @apple Thanks!!"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the apply test data\n",
    "testing = pd.read_excel('data/testing_data.xlsx', header=None)\n",
    "testing_answer = pd.read_excel('data/testing_data_answers.xlsx', header=None)\n",
    "testing = testing.rename(columns={i: col for i, col in enumerate(['TweetId', \"TweetText\"])})\n",
    "testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the clean tweet data as list\n",
    "sent_list_test = clean_texts(np.array(testing['TweetText'].values), tagging=True)\n",
    "# transform to the TF-IDF\n",
    "matrix_test = tfidf_vect.transform(sent_list_test)\n",
    "test_data = matrix_test.toarray()\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_voting(models, X_test):\n",
    "    # Collect predictions from each model\n",
    "    predictions = [model.predict(X_test) for model in models]\n",
    "\n",
    "    # Convert list of predictions to a numpy array for easy manipulation\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Use majority voting for final prediction\n",
    "    final_prediction = np.array([statistics.mode(predictions[:, i]) for i in range(predictions.shape[1])])\n",
    "\n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.060344827586206"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "# Random Forest\n",
    "test_data_pred_cat = predict_with_voting(nb_models, test_data)\n",
    "sum(testing_answer[1].values == test_data_pred_cat) / len(testing_answer[1].values) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.603448275862068"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "test_data_pred_cat = predict_with_voting(rf_models, test_data)\n",
    "sum(testing_answer[1].values == test_data_pred_cat) / len(testing_answer[1].values) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41.16379310344828"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural Network\n",
    "\n",
    "# Averaging weights of the models\n",
    "weights = [model.get_weights() for model in nw_models]\n",
    "new_weights = list()\n",
    "\n",
    "for weights_list_tuple in zip(*weights):\n",
    "    new_weights.append(\n",
    "        np.array([np.array(weights_).mean(axis=0) for weights_ in zip(*weights_list_tuple)])\n",
    "    )\n",
    "\n",
    "# Create a new model with the same architecture\n",
    "aggregated_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Set the averaged weights\n",
    "aggregated_model.set_weights(new_weights)\n",
    "\n",
    "# show the predicted labels\n",
    "test_data_pred = aggregated_model.predict(test_data)\n",
    "# convert to the label and invert the encoded labels\n",
    "test_data_pred_cat = label_encoder.inverse_transform(np.argmax(test_data_pred, axis=1))\n",
    "# Accuacy\n",
    "sum(testing_answer[1].values == test_data_pred_cat) / len(testing_answer[1].values) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write predicted target value\n",
    "\n",
    "with open('prediction.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(list(test_data_pred_cat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agg_neural_network.joblib']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "import joblib\n",
    "joblib.dump(aggregated_model, 'agg_neural_network.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
