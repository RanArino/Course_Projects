{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for sharing your idea. I will try to explain the math equations at each step and evaluate your method.\n",
    "\n",
    "First, let me define some notation and variables. Let X be the matrix of features, y be the vector of target values, theta be the vector of parameters, m be the number of training examples, n be the number of features, alpha be the learning rate, and J(theta) be the cost function. Assume that X has a column of ones for the intercept term, and that X and y are normalized and standardized.\n",
    "\n",
    "- Taking the best parameter at each step by normal equation; the training data is always the last 10 years data; once the newly updated data, the training data will be shifted.\n",
    "    - The normal equation is given by:\n",
    "\n",
    "    $$\\theta = (X^TX)^{-1}X^Ty$$\n",
    "\n",
    "    - This equation computes the optimal parameters that minimize the cost function J(theta), which is defined as:\n",
    "\n",
    "    $$J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "    - where $h_\\theta(x^{(i)})$ is the hypothesis function that predicts the value of y for a given x, and is defined as:\n",
    "\n",
    "    $$h_\\theta(x^{(i)}) = \\theta^Tx^{(i)}$$\n",
    "\n",
    "    - The normal equation requires to invert the matrix $X^TX$, which has a dimension of n x n. This can be computationally expensive and numerically unstable when n is large or when X is ill-conditioned. Therefore, this method may not be suitable for high-dimensional or noisy data.\n",
    "\n",
    "- Get the mean squared error, which is calculated by taking the sum of squared of the difference between the predicted values (from the current parameters and the last 10 years data) and the actual data.\n",
    "    - The mean squared error (MSE) is given by:\n",
    "\n",
    "    $$MSE = \\frac{1}{m}\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "    - This is equivalent to J(theta) multiplied by 2/m. Therefore, minimizing MSE is equivalent to minimizing J(theta). However, MSE is sensitive to outliers and assumes homoscedasticity and normality of the error term. Therefore, this method may not be robust or valid for data that violates these assumptions.\n",
    "\n",
    "- Update the parameters for the next step by subtracting the mean squared error * learning rate from the current parameters.\n",
    "    - This update rule is given by:\n",
    "\n",
    "    $$\\theta := \\theta - \\alpha MSE$$\n",
    "\n",
    "    - This rule updates all parameters simultaneously by subtracting a scalar value from them. However, this rule does not take into account the gradient of J(theta) with respect to each parameter, which indicates how much each parameter contributes to the cost function and how much it should change to reduce it. Therefore, this rule may not guarantee the convergence or optimality of the parameters, and may even cause them to diverge or oscillate around the minimum.\n",
    "\n",
    "In summary, your idea has some drawbacks and limitations that may affect its performance and validity. A possible improvement is to use a gradient-based method instead of an error-based method, such as gradient descent or its variants. Gradient descent updates each parameter by taking steps in the opposite direction of its partial derivative with respect to J(theta), which is given by:\n",
    "\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m}\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)}$$\n",
    "\n",
    "The update rule for gradient descent is then:\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}$$\n",
    "\n",
    "This rule ensures that each parameter moves towards the direction that decreases J(theta) most rapidly, and converges to a local minimum or a global minimum if J(theta) is convex. Gradient descent can also be modified to use different learning rates, momentum terms, or adaptive methods to improve its speed and stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "<hr style=\"border:2px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, you are right. If you only use the newly updated data to update your model, then you are using a stochastic gradient descent (SGD) approach. SGD is a variant of gradient descent that updates the parameters using only a single or a small batch of data at each iteration, instead of using the entire dataset. This can reduce the computational cost and memory requirement of the algorithm, and also introduce some randomness and noise that can help the model escape from local minima or saddle points.\n",
    "\n",
    "The calculations for SGD are similar to those for gradient descent, except that you use a different subset of data at each iteration. Let me show you an example with a single data point. Suppose you have a new data point $(x^{(i)}, y^{(i)})$ that arrives at time t, and you want to update your parameters $\\theta$ using SGD. You can do the following steps:\n",
    "\n",
    "- Calculate the hypothesis function $h_\\theta(x^{(i)}) = \\theta^Tx^{(i)}$, which predicts the value of y for the given x.\n",
    "- Calculate the error term $e^{(i)} = h_\\theta(x^{(i)}) - y^{(i)}$, which measures the difference between the predicted value and the actual value.\n",
    "- Calculate the gradient of the cost function $J(\\theta)$ with respect to each parameter $\\theta_j$, which is given by $\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = e^{(i)}x_j^{(i)}$. Note that this is different from the batch gradient descent, where you have to sum over all data points.\n",
    "- Update each parameter $\\theta_j$ by taking a step in the opposite direction of its gradient, which is given by $\\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\theta_j - \\alpha e^{(i)}x_j^{(i)}$. Note that this is similar to the batch gradient descent, except that you use a different error term and feature value at each iteration.\n",
    "\n",
    "You can repeat these steps for each new data point that arrives, and your model will gradually converge to a local minimum or a global minimum if $J(\\theta)$ is convex. You can also use a small batch of data instead of a single data point, and calculate the average gradient and error term over the batch.\n",
    "\n",
    "SGD has some advantages over batch gradient descent, such as:\n",
    "- It can handle large or streaming data more efficiently and effectively, since it does not require to store or process all the data at once.\n",
    "- It can adapt to changing data more quickly and smoothly, since it updates the parameters more frequently and incrementally.\n",
    "- It can avoid getting stuck in local minima or saddle points, since it introduces some randomness and noise that can help the model explore different regions of the cost function.\n",
    "\n",
    "However, SGD also has some drawbacks, such as:\n",
    "- It can be noisy and unstable, since it updates the parameters based on a single or a small batch of data that may not represent the true gradient or error term.\n",
    "- It can oscillate around the minimum or overshoot it, since it uses a fixed learning rate that may not be optimal for different stages of the convergence process.\n",
    "- It can be sensitive to outliers or noisy data, since it updates the parameters based on every data point regardless of its quality or relevance.\n",
    "\n",
    "Therefore, SGD requires careful tuning of the learning rate and other hyperparameters, such as batch size, momentum term, or adaptive methods, to improve its speed and stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic net Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Elastic Net regularization is a linear combination of L1 and L2 regularizations. It adds both L1 and L2 penalties to the loss function:\n",
    "\n",
    "$$ J(\\theta) = MSE(\\theta) + r \\cdot \\alpha \\cdot ||\\theta||_1 + \\frac{1-r}{2} \\cdot \\alpha \\cdot ||\\theta||_2^2 $$\n",
    "\n",
    "where:\n",
    "- $J(\\theta)$ is the cost function\n",
    "- $MSE(\\theta)$ is the Mean Squared Error\n",
    "- $r$ is the mixing parameter between Ridge ($r=0$) and Lasso ($r=1$)\n",
    "- $\\alpha$ is the regularization parameter\n",
    "- $||\\theta||_1$ is the L1 norm (sum of absolute values of the parameters)\n",
    "- $||\\theta||_2^2$ is the squared L2 norm (sum of squares of the parameters)\n",
    "\n",
    "The derivative of this cost function with respect to the parameters $\\theta$ is:\n",
    "\n",
    "$$ \\frac{d}{d\\theta} J(\\theta) = \\frac{d}{d\\theta} MSE(\\theta) + r \\cdot \\alpha \\cdot sign(\\theta) + (1-r) \\cdot \\alpha \\cdot \\theta $$\n",
    "\n",
    "where $sign(\\theta)$ is the sign function, which outputs -1 for negative inputs, 0 for zero, and 1 for positive inputs.\n",
    "\n",
    "In Python, you can compute this derivative as follows:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def elastic_net_derivative(theta, X, y, alpha, r):\n",
    "    n = len(X)\n",
    "    y_hat = np.dot(X, theta)\n",
    "    d_mse = 2/n * np.dot(X.T, y_hat - y)\n",
    "    d_l1 = r * alpha * np.sign(theta)\n",
    "    d_l2 = (1 - r) * alpha * theta\n",
    "    return d_mse + d_l1 + d_l2\n",
    "```\n",
    "\n",
    "In this code:\n",
    "- `X` is the matrix of input features,\n",
    "- `y` is the vector of target values,\n",
    "- `alpha` is the regularization parameter,\n",
    "- `r` is the mixing parameter,\n",
    "- `theta` are the parameters of your model. \n",
    "\n",
    "This function computes and returns the derivative of the Elastic Net cost function with respect to `theta`. The derivative will be used in gradient descent to update the parameters. Please note that this code does not handle the bias term separately; you may want to do so in your implementation. Also, remember to scale your features before applying Elastic Net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def gradient_descent(X, y, t, s, eta=0.01, alpha=1, lambda_=0.5):\n",
    "    \"\"\"\n",
    "    Return the following three matrix (dtype: np.array)\n",
    "    - \"theta\"  -> parameters (intercept + coefficients) at each step\n",
    "    - \"y_hats\" -> predicted values at each step\n",
    "    - \"error\"  -> prediction errors (actual - predicted values); SSE\n",
    "\n",
    "    Parameters:\n",
    "    - \"X\": np.array -> independent variables\n",
    "    - \"y\": np.array -> target variables\n",
    "    - \"t\": int -> number of data that were used for the initial parameter creation.\n",
    "    - \"s\": int -> scope of the latest data for parameter updates \n",
    "    - \"eta\": learning rate for gradient descent\n",
    "    - \"alpha\": how strength the regularization is.\n",
    "    - \"lambda_\": balancing between ridge and lasso regularization.\n",
    "\n",
    "    Brief Steps:\n",
    "    - Initialize matries for theta, y_hats, error.\n",
    "    - Apply a given number of data (\"t\") to the mutiple linear regression (normal equation).\n",
    "    - Define the initial parameters from the trained model.\n",
    "    - At each step (total steps are len(y) - t):\n",
    "        - Get a single pair of unfamilar data; both X and y.\n",
    "        - Predict the target (\"y_hats\") based on the latest parameters(\"theta[i]\").\n",
    "        - Calculate the difference between actual and predicted values; \"error[i]\".\n",
    "        - Update parameters for the next step (\"theta[i+1]\").\n",
    "    \"\"\"\n",
    "\n",
    "    # define all matrix to be returned\n",
    "    theta = np.zeros((len(y)-t + 1, 6))\n",
    "    y_hats = np.zeros((len(y)-t, 1))\n",
    "    error = np.zeros((len(y)-t, 1))\n",
    "    # Modify the matrix of features; adding bias \n",
    "    #X = np.insert(X[:], 0, 1, axis=1)\n",
    "\n",
    "    # define elastic net derivative\n",
    "    def elastic_net_der(theta, X, y, n=s, a_=alpha, l_=lambda_):\n",
    "        # reshape\n",
    "        X = X.reshape(n, -1)\n",
    "        y_hat = np.dot(X, theta).reshape(-1, 1)\n",
    "        # error weighted feature\n",
    "        ewf = 2/n * np.dot(X.T, y_hat - y).reshape(1, -1)\n",
    "        d_l1 = l_ * a_ * np.sign(theta)\n",
    "        d_l2 = (1 - l_) * a_ * theta\n",
    "        return ewf + d_l1 + d_l2\n",
    "    \n",
    "    # initial training\n",
    "    init_X, init_y = X[0:t], y[0:t]\n",
    "    # obtain the initial parameters based on normal equation form\n",
    "    theta[0] = np.linalg.inv(init_X.T.dot(init_X)).dot(init_X.T).dot(init_y).reshape(1,-1)\n",
    "    \n",
    "    # incremental learnings\n",
    "    for i, idx in enumerate(range(t, len(y))):\n",
    "        # get new data (X_i includes bias)\n",
    "        X_i, y_i = X[idx] , y[idx]\n",
    "        # predicted variable\n",
    "        y_hats[i] = np.dot(X_i, theta[i])\n",
    "        # predicted error\n",
    "        error[i] =  (y_hats[i] - y_i)\n",
    "        # start gradient descent based on the data scope (\"s\")\n",
    "        # if scope is > 1, taking care of the predicted error from the recent data over a given scope ('s')\n",
    "        if s > 1:\n",
    "            # get the latest data based on the scope ('S')\n",
    "            X_, y_ = X[idx-s+1:idx+1], y[idx-s+1:idx+1]\n",
    "            derivative = elastic_net_der(theta[i], X_, y_)\n",
    "            theta[i+1] = theta[i] - eta * derivative\n",
    "\n",
    "        # if scope is 1, only taking care of the predicted error from the most recent data \n",
    "        else:\n",
    "            derivative = elastic_net_der(theta[i], X_i, y_i)\n",
    "            theta[i+1] = theta[i] - eta * derivative\n",
    "            \n",
    "    return theta, y_hats, error\n",
    "\n",
    "def evaluation(X, y, t, theta, y_hats, error):\n",
    "    \"\"\"\n",
    "    Return the data frame; the following measureas by brackward eliminations:\n",
    "    - Root Mean Square Error (rmse)\n",
    "    - Standatd Error of Estimate (se)\n",
    "    - Coefficient of Determination (r2)\n",
    "    - Adjusted Coefficient of Determination (adj_r2)\n",
    "\n",
    "    Parameters:\n",
    "    - \"t\": number of months that were used for the initial training data.\n",
    "    - \"X\": independent variables\n",
    "    - \"y\": the actual target value (whole period)\n",
    "    - \"theta\": all parameters (intercept & coefficients) at each step\n",
    "    - \"y_hats\": the predicted target value at each step\n",
    "    - \"error\": difference between actual and predicted values at each step\n",
    "\n",
    "    Requirement: len(y[t:]) == len(y_hats)\n",
    "    \"\"\"\n",
    "    # (0): Define Variables\n",
    "    #  number of observations and features (excluding bias)\n",
    "    n, k = len(y_hats), len(theta[0]) - 1\n",
    "    #  measures matrix\n",
    "    mm = np.zeros((k+1, 4))\n",
    "    # assign the data frame index and columns\n",
    "    rows = ['original'] + [f'theta{i+1}=0' for i in range(k)]\n",
    "    cols = ['rmse', 'se', 'r2', 'adj_r2']\n",
    "    #  mean of actual \"y\" over the \"t\" months\n",
    "    #y_mean = np.array([y[i:i+t].mean() for i in range(len(y)-t)]).reshape(-1, 1)\n",
    "    y_mean = np.mean(y[t:])\n",
    "    #  sum of square total\n",
    "    sst = np.sum((y[t:] - y_mean)**2)\n",
    "    #  define feature matrix and target based on \"t\"\n",
    "    X_, y_ = np.insert(X[t:n+t], 0, 1, axis=1), y[t:]\n",
    "\n",
    "    #  number of coefficients\n",
    "    for i in range(k+1):\n",
    "        # simply applying the given error\n",
    "        if i == 0:\n",
    "            error_ = error\n",
    "        # conduct the backward elimination\n",
    "        else:\n",
    "            # copy the parameters matrix\n",
    "            theta_ = theta[:n].copy()\n",
    "            # change a particular coefficient to 0 arbitrarily.\n",
    "            theta_[:, i] = 0\n",
    "            # based on revised parameters, get the predicted value\n",
    "            y_hats_ = np.sum(X_ * theta_, axis=1).reshape(-1, 1)\n",
    "            # predicted error\n",
    "            error_ = y_ - y_hats_    \n",
    "    \n",
    "        # Calculate Measures (rmse, se, r2, adj_r2, in order)\n",
    "        sse = np.sum(error_**2)\n",
    "        mm[i, 0] = np.sqrt((error_**2).mean()) \n",
    "        mm[i, 1] = np.sqrt(sse / (n - k - 1))\n",
    "        mm[i, 2] = 1 - sse/sst\n",
    "        mm[i, 3] = 1 - (sse/(n - k -1))/(sst/(n-1))\n",
    "         \n",
    "    return pd.DataFrame(data=mm, index=rows, columns=cols)\n",
    "\n",
    "\n",
    "def online_learning(t, X, y, alpha=0.01, lambda_=0.5):\n",
    "    \"\"\"\n",
    "    Return the following three matrix (dtype: np.array)\n",
    "    - \"theta\"  -> parameters (intercept + coefficients) at each step\n",
    "    - \"y_hats\" -> predicted values at each step\n",
    "    - \"error\"  -> prediction errors (actual - predicted values); SSE\n",
    "\n",
    "    Parameters:\n",
    "    - \"t\": int -> number of months that were used for the initial training data.\n",
    "    - \"X\": np.array -> independent variables\n",
    "    - \"y\": np.array -> target variables\n",
    "    - \"alpha\": learning rate for gradient descent\n",
    "    - \"lambda_\": hyperparameter for the elastic net regularization.\n",
    "\n",
    "    Brief Steps:\n",
    "    - Initialize matries for theta, y_hats, error.\n",
    "    - Apply a given time ranges (\"t\") of the dataset to the mutiple linear regression.\n",
    "    - Define the initial parameters from the trained model.\n",
    "    - For each new data point (incremental learning):\n",
    "        - Predict the target; \"y_hats\".\n",
    "        - Calculate the difference between actual and predicted values; \"error\"\n",
    "        - Update parameters by (stochastic) gradient descent with elastic regularization; \"theta\"\n",
    "    \"\"\"\n",
    "    # define all matrix to be returned\n",
    "    theta = np.zeros((len(y)-t + 1, 6))\n",
    "    y_hats = np.zeros((len(y)-t, 1))\n",
    "    error = np.zeros((len(y)-t, 1))\n",
    "    # Modify the matrix of features; adding bias \n",
    "    X = np.insert(X[:], 0, 1, axis=1)\n",
    "    \n",
    "    # initial training\n",
    "    init_X, init_y = X[0:t], y[0:t]\n",
    "    # obtain the initial parameters based on normal equation form\n",
    "    theta[0] = np.linalg.inv(init_X.T.dot(init_X)).dot(init_X.T).dot(init_y).reshape(1,-1)\n",
    "    \n",
    "    # incremental learnings\n",
    "    for i, idx in enumerate(range(t, len(y))):\n",
    "        # get new data (X_i includes bias)\n",
    "        X_i, y_i = X[idx] , y[idx]\n",
    "        # predicted variable\n",
    "        y_hats[i] = np.dot(X_i, theta[i])\n",
    "        # predicted error\n",
    "        error[i] =  (y_i - y_hats[i])\n",
    "        # the gradient of the loss function with respect to the new observation (normal: X_i * error[i])\n",
    "        gradient = -2 * X_i * error[i] + 2 * lambda_ * theta[i] + (1-lambda_) * np.sign(theta[i])\n",
    "        # update all parameters by stochastic gradient descent\n",
    "        theta[i+1] = theta[i] - alpha * gradient\n",
    "\n",
    "    return theta, y_hats, error\n",
    "\n",
    "def batch_learning(t, X, y, labmda_=0.5):\n",
    "    \"\"\"\n",
    "    Return the following three matrix (dtype: np.array)\n",
    "    - \"theta\"  -> parameters (intercept + coefficients) at each step\n",
    "    - \"y_hats\" -> predicted values at each step\n",
    "    - \"error\"  -> prediction errors\n",
    "\n",
    "    Parameters:\n",
    "    - \"t\": int -> number of months that were used for the initial training data.\n",
    "    - \"X\": np.array -> independent variables\n",
    "    - \"y\": np.array -> target variables\n",
    "    - \"lambda_\": hyperparameter for the elastic net regularization.\n",
    "\n",
    "    Brief Steps:\n",
    "    - Initialize matries for theta, y_hats, error.\n",
    "    - Train the model with a given time ranges (\"t\") of the dataset.\n",
    "    - For each new data point (batch learning):\n",
    "        - get all parameters (intercept and coefficients) by the least square method; \"theta\"\n",
    "        - Predict the target value; \"y_hats\".\n",
    "        - Calculate the difference between actual and predicted values; \"error\"\n",
    "    \"\"\"\n",
    "    # define all matrix to be returned\n",
    "    theta = np.zeros((len(y)-t + 1, 6))\n",
    "    y_hats = np.zeros((len(y)-t, 1))\n",
    "    error = np.zeros((len(y)-t, 1))\n",
    "\n",
    "    # batch learning\n",
    "    for i, idx in enumerate(range(t, len(y))):\n",
    "        # get the recent \"t\" months data (X_i includes bias)\n",
    "        X_i, y_i = np.insert(X[i:idx], 0, 1, axis=1) , y[i:idx]\n",
    "        # fit the training data (normal equation form)\n",
    "        theta[i] = np.linalg.inv(X_i.T.dot(X_i)).dot(X_i.T).dot(y_i).reshape(1,-1)\n",
    "        # predicted value\n",
    "        X_new = np.append(np.array([1]), X[idx])\n",
    "        y_hats[i] = np.dot(theta[i], X_new)\n",
    "        # predicted error\n",
    "        error[i] = y[idx] - y_hats[i]\n",
    "\n",
    "    # trained the most recent data\n",
    "    last = len(y)\n",
    "    X_i, y_i = np.insert(X[last-t:last], 0, 1, axis=1) , y[last-t:last]\n",
    "    theta[last-t] = np.linalg.inv(X_i.T.dot(X_i)).dot(X_i.T).dot(y_i).reshape(1,-1)\n",
    "\n",
    "    return theta, y_hats, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
